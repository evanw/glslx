namespace GLSLX {
  enum OutputFormat {
    JSON
    JS
    CPP
    SKEW
    RUST
  }

  enum RenameSymbols {
    ALL
    INTERNAL_ONLY
    NONE
  }

  class CompilerOptions {
    var compactSyntaxTree = true
    var removeWhitespace = true
    var renameSymbols = RenameSymbols.ALL
    var trimSymbols = true
    var fileAccess fn(string, string) Source = null
  }

  enum ExtensionBehavior {
    DEFAULT
    DISABLE
    ENABLE
    REQUIRE
    WARN
  }

  class CompilerData {
    const currentExtensions StringMap<ExtensionBehavior> = {}
    var fileAccess fn(string, string) Source
    var _nextSymbolID = 0

    def nextSymbolID int {
      _nextSymbolID++
      return _nextSymbolID
    }

    def extensionBehavior(name string) ExtensionBehavior {
      return currentExtensions.get(name, .DEFAULT)
    }
  }

  class CompilerResult {
    const shaders List<Source>
    const renaming StringMap<string>

    def output(format OutputFormat) string {
      switch format {
        case .JSON {
          var map dynamic = {}
          renaming.keys.each(key => map[key] = renaming[key])
          return dynamic.JSON.stringify({
            "shaders": shaders == null ? null : shaders.map<dynamic>(source => ({
              "name": source.name,
              "contents": source.contents,
            })),
            "renaming": map,
          }, null, 2) + "\n"
        }

        case .JS {
          if shaders != null {
            var code = ""
            for shader in shaders {
              code += "export const GLSLX_SOURCE_\(_transformName(shader.name)) = \(dynamic.JSON.stringify(shader.contents))\n"
            }
            if renaming != null && !renaming.keys.isEmpty {
              code += "\n"
              for name in renaming.keys {
                code += "export const GLSLX_NAME_\(_transformName(name)) = \(dynamic.JSON.stringify(renaming[name]))\n"
              }
            }
            return code
          }
        }

        case .CPP {
          if shaders != null {
            var code = ""
            code += "#ifndef GLSLX_STRINGS_H\n"
            code += "#define GLSLX_STRINGS_H\n"
            code += "\n"
            for shader in shaders {
              code += "static const char *GLSLX_SOURCE_\(_transformName(shader.name)) = \(dynamic.JSON.stringify(shader.contents));\n"
            }
            code += "\n"
            if renaming != null {
              for name in renaming.keys {
                code += "static const char *GLSLX_NAME_\(_transformName(name)) = \(dynamic.JSON.stringify(renaming[name]));\n"
              }
              code += "\n"
            }
            code += "#endif\n"
            return code
          }
        }

        case .SKEW {
          if shaders != null {
            var code = ""
            for shader in shaders {
              code += "const GLSLX_SOURCE_\(_transformName(shader.name)) = \(dynamic.JSON.stringify(shader.contents))\n"
            }
            if renaming != null && !renaming.keys.isEmpty {
              code += "\n"
              for name in renaming.keys {
                code += "const GLSLX_NAME_\(_transformName(name)) = \(dynamic.JSON.stringify(renaming[name]))\n"
              }
            }
            return code
          }
        }

        case .RUST {
          if shaders != null {
            var code = ""
            for shader in shaders {
              code += "pub static GLSLX_SOURCE_\(_transformName(shader.name)): &str = \(dynamic.JSON.stringify(shader.contents));\n"
            }
            if renaming != null && !renaming.keys.isEmpty {
              code += "\n"
              for name in renaming.keys {
                code += "pub static GLSLX_NAME_\(_transformName(name)): &str = \(dynamic.JSON.stringify(renaming[name]));\n"
              }
            }
            return code
          }
        }
      }
      return null
    }

    def _transformName(name string) string {
      return (name as dynamic).replace(dynamic.RegExp.new("([a-z0-9])([A-Z])", "g"), "$1_$2").toUpperCase()
    }
  }
}

namespace GLSLX.Compiler {
  def typeCheck(log Log, sources List<Source>, options CompilerOptions) Node {
    if log.hasErrors {
      return null
    }

    # Generate tokens once
    sources.prepend(Source.new("<api>", API))
    for source in sources {
      source.tokens = Tokenizer.tokenize(log, source, .COMPILE)
    }

    var global = Node.createGlobal
    var scope = Scope.new(.GLOBAL, null)
    var data = CompilerData.new(options.fileAccess)
    var resolver = Resolver.new(log, data)

    # Parse everything next
    for source in sources {
      Parser.parse(log, source.tokens, global, data, scope, resolver)
    }

    # Then run type checking
    resolver.resolveGlobal(global)

    # Always return even when there were errors since the partial result is still useful
    return global
  }

  def compile(log Log, sources List<Source>, options CompilerOptions) CompilerResult {
    if log.hasErrors {
      return null
    }

    # Generate tokens once
    sources.prepend(Source.new("<api>", API))
    for source in sources {
      source.tokens = Tokenizer.tokenize(log, source, .COMPILE)
    }

    var global = Node.createGlobal
    var scope = Scope.new(.GLOBAL, null)
    var data = CompilerData.new(options.fileAccess)
    var resolver = Resolver.new(log, data)

    # Parse everything next
    for source in sources {
      Parser.parse(log, source.tokens, global, data, scope, resolver)
    }

    # Then run type checking
    resolver.resolveGlobal(global)

    if log.hasErrors {
      return null
    }

    # Multiple export mode is more complicated. Everything is already compiled,
    # and in theory we could quickly export all shaders from that, but in
    # practice it's simpler if the source code is just compiled over again once
    # per shader.
    var names List<string> = []
    var globals List<Node> = []
    for root in _collectAllExportedFunctions(scope) {
      var shaderGlobal = Node.createGlobal
      var shaderScope = Scope.new(.GLOBAL, null)
      var shaderData = CompilerData.new(options.fileAccess)
      var shaderLog = Log.new
      var shaderResolver = Resolver.new(shaderLog, shaderData)

      # Parse everything again
      for source in sources {
        Parser.parse(shaderLog, source.tokens, shaderGlobal, shaderData, shaderScope, shaderResolver)
      }

      # Flow types through the tree
      shaderResolver.resolveGlobal(shaderGlobal)

      # Optimize it and trim it down
      _unexportAllFunctionsExcept(shaderScope, root)
      Rewriter.rewrite(shaderGlobal, shaderData, options)
      globals.append(shaderGlobal)
      names.append(root.name)
    }

    # Rename everything together
    var shaders List<Source> = []
    var renaming = Renamer.rename(globals, options)
    for i in 0..names.count {
      shaders.append(Source.new(names[i], Emitter.emit(globals[i], options)))
    }
    return CompilerResult.new(shaders, renaming)
  }

  def _collectAllExportedFunctions(scope Scope) List<FunctionSymbol> {
    var symbols List<FunctionSymbol> = []
    for symbol in scope.symbols.values {
      if symbol.isFunction && symbol.isExported {
        symbols.append(symbol.asFunction)
      }
    }
    return symbols
  }

  def _unexportAllFunctionsExcept(scope Scope, function FunctionSymbol) {
    for symbol in scope.symbols.values {
      if symbol.id != function.id {
        symbol.flags &= ~.EXPORTED
      } else {
        symbol.name = "main"
        var sibling = symbol.asFunction.sibling
        if sibling != null {
          sibling.name = symbol.name
        }
      }
    }
  }
}
